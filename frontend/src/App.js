import React from "react";
import './App.css';
import {
  Button,
  Box,
  Container,
  Grid,
  IconButton,
  List,
  ListItem,
  ListItemText,
  Paper,
  Typography,
  FormControlLabel,
  Switch,
  TextField,
} from "@mui/material";
//éå¸¸å¤šçš„å®¹å™¨ä»¥åŠå…ƒä»¶å¯ä»¥ä½¿ç”¨ï¼Œå¯ä»¥æŸ¥æŸ¥çœ‹ä»–çš„materialè³‡æ–™åº«æœ‰ä»€éº¼å¯ä»¥åˆ©ç”¨
import {
  useState,
  useRef,
  useEffect
} from "react";
import { useTheme } from '@mui/material/styles';
import {
  styled,
  keyframes
} from '@mui/system';
import VolumeUpIcon from '@mui/icons-material/VolumeUp';
import MicRecorder from 'mic-recorder-to-mp3';
import FiberManualRecordIcon from '@mui/icons-material/FiberManualRecord'
import MicIcon from '@mui/icons-material/Mic'
import MoreHorizIcon from '@mui/icons-material/MoreHoriz';
import { API, Amplify } from "aws-amplify";
import CloudUploadIcon from "@mui/icons-material/CloudUpload";
import SendIcon from "@mui/icons-material/Send"

Amplify.configure({

  Auth: {
    mandatorySignIn: false,
  },
  API: {
    endpoints: [
      {
        name: "api",
        endpoint: "https://ixbcg6vgsc.execute-api.ap-northeast-1.amazonaws.com/dev/get-answer",
      }
    ]
  }
});

function filterMessageObjects(list) {
  return list.map(({ role, content }) => ({ role, content }));
}

function App() {
  const ChatHeader = () => {
    // å®šç¾©äº†ä¸€å€‹åç‚º ChatHeader çš„ React å‡½å¼å…ƒä»¶ï¼Œä¹Ÿå°±æ˜¯æ¨™é¡Œåˆ—ã€‚
    return (
      <Typography variant="h4" align="center" gutterBottom>
        {/* è¨­ç½®æ–‡å­—çš„æ¨£å¼è®Šé«”ç‚º "h4"ï¼ˆæ¨™é¡Œï¼‰ï¼Œæ°´å¹³ç½®ä¸­ï¼Œä¸¦åœ¨æ–‡å­—ä¸‹æ–¹å¢åŠ ä¸€å€‹é–“è·ï¼Œè®“æ–‡å­—èˆ‡ä¸‹æ–¹çš„å…§å®¹æœ‰ä¸€äº›é–“éš”ã€‚ */}
        {/* Typographyæ˜¯ä¸€å€‹å¯ä»¥æŠŠhtmlä½µå…¥jsçš„æŠ€è¡“ï¼Œè¦ä¿®æ”¹ä»€éº¼æ ¼å¼ç›´æ¥åœ¨é€™é‚Šä¿®æ”¹å³å¯ï¼Œè »é…·çš„ */}
        Voice Chatbot
      </Typography>
    )
  }

  const mockMessages = [
    {
      role: 'assistant',
      content: 'Hello, how can I help you today?',
      text: 'Hello, how can I help you today?'
    },
  ]
  const [messages, setMessages] = useState(mockMessages);
  const [message, setMessage] = useState("");
  const UserMessage = styled('div', { shouldForwardProp: (prop) => prop !== 'audio' })`
  position: relative;
  background-color: ${({ theme }) => theme.palette.primary.main};
  color: ${({ theme }) => theme.palette.primary.contrastText};
  padding: ${({ theme }) => theme.spacing(1, 2)};
  padding-right: ${({ theme, audio }) => (audio ? theme.spacing(6) : theme.spacing(2))};
  border-radius: 1rem;
  border-top-right-radius: 0;
  align-self: flex-end;
  max-width: 80%;
  word-wrap: break-word;
`;

  const AgentMessage = styled('div')`
  position: relative;
  background-color: ${({ theme }) => theme.palette.grey[300]};
  color: ${({ theme }) => theme.palette.text.primary};
  padding: ${({ theme }) => theme.spacing(1, 2)};
  border-radius: 1rem;
  border-top-left-radius: 0;
  align-self: flex-end;
  max-width: 80%;
  word-wrap: break-word;
`;

  const MessageWrapper = styled('div')`
  display: flex;
  margin-bottom: ${({ theme }) => theme.spacing(1)};
  justify-content: ${({ align }) => (align === 'user' ? 'flex-end' : 'flex-start')};
  `;
  // å¦‚æœå‚³é€è¨Šæ¯çš„äººæ˜¯userï¼Œå°±flex-endï¼Œå¦‚æœæ˜¯agentå°±flex-start

  const ChatMessages = ({ messages }) => {
    const theme = useTheme();
    const bottomRef = useRef(null);
    const scrollToBottom = () => {
      if (bottomRef.current) {
        if (typeof bottomRef.current.scrollIntoViewIfNeeded === 'function') {
          bottomRef.current.scrollIntoViewIfNeeded({ behavior: 'smooth' });
        } else {
          bottomRef.current.scrollIntoView({ behavior: 'smooth' });
        }
      }
    };
    useEffect(() => {
      scrollToBottom();
    }, [messages]);
    // ç¢ºä¿æœ‰æ–°è¨Šæ¯çš„æ™‚å€™ä¹Ÿæœƒç¹¼çºŒå¾€ä¸‹æ²åˆ°åº•
    // 1. å…ˆç¢ºèªbottomRef.currentæœ‰æ²’æœ‰è¢«å®šç¾©ï¼Œå¦‚æœæœ‰ï¼Œç¢ºèªscrollIntoViewIfNeededæ˜¯å¯ä½¿ç”¨çš„ã€‚
    // 2. å¦‚æœå¯ä»¥çš„è©±ï¼Œå‘¼å«scrollIntoViewIfNeededä¾†é †æš¢åœ°å¾€ä¸‹æ»‘å‹•åˆ°åº•ï¼ˆé€™å€‹functionä¸ä¸€å®šæ‰€æœ‰ç€è¦½å™¨éƒ½å¯ä»¥ç”¨ï¼Œsafariå°±ä¸è¡Œï¼‰

    return (
      <Container>
        <Box sx={{ width: '100%', mt: 4, maxHeight: 300, minHeight: 300, overflow: 'auto' }}>
          <Paper elevation={0} sx={{ padding: 2 }}>
            <List>
              {messages.map((message, index) => (
                <ListItem key={index} sx={{ padding: 0 }}>
                  <ListItemText
                    sx={{ margin: 0 }}
                    primary={
                      <MessageWrapper align={message.role}>
                        {message.role === 'user' ? (
                          <>
                            <UserMessage theme={theme} audio={message.audio}>
                              {message.text}
                              {message.audio && (
                                <IconButton
                                  size="small"
                                  sx={{
                                    position: 'absolute',
                                    top: '50%',
                                    right: 8,
                                    transform: 'translateY(-50%)'
                                  }}
                                  onClick={() => message.audio.play()}
                                >
                                  {/* IconButtonçš„æ ¼å¼è¨­å®š */}
                                  <VolumeUpIcon fontSize="small" />
                                </IconButton>
                              )}
                            </UserMessage>
                          </>
                        ) : (
                          <AgentMessage theme={theme}>
                            {message.text}
                          </AgentMessage>
                        )}
                      </MessageWrapper>
                    }
                  />
                </ListItem>
              ))}
              <div ref={bottomRef} />
              {/* å¢åŠ é€™å€‹bottomRefåƒç…§ä¾†è®“è‡ªå‹•æ²å‹•åŠŸèƒ½æ­£å¸¸ */}
            </List>
          </Paper>
        </Box>
      </Container>

      // é€™é‚Šç”¨Containerä¾†åŒ…è£æ•´å€‹æ±è¥¿ï¼Œå†ç”¨BoxæŠŠå…¨éƒ¨åŒ…èµ·ä¾†ï¼Œä¸¦å¸¶æœ‰ç‰¹å®šçš„å¯¬ã€é‚Šç•Œã€æœ€å¤§é«˜åº¦ç­‰ï¼Œ
      // ç„¶å¾Œå†ç”¨Paperè®“èŠå¤©å€åŸŸå¾èƒŒæ™¯ä¸­å‡¸é¡¯å‡ºä¾†ï¼Œæœ€å¾Œå†ç”¨Listä¾†æ”¾ç½®èŠå¤©è¨Šæ¯
    )
  }
  const [isAudioResponse, setIsAudioResponse] = useState(false);

  const handleSendMessage = async () => {
    //å…ˆæª¢æŸ¥è¨Šæ¯æ˜¯å¦ç‚ºç©º
    if (message.trim() !== "") {
      //æ›´æ–°messagesçš„é™£åˆ—ï¼Œå°‡æ–°è¨Šæ¯åŠ é€²å»
      setMessages((prevMessages) => [
        ...prevMessages,
        { role: "user", content: message, text: message, audio: null },
      ]);

      //æ¸…ç©ºæ‰“å­—å€
      setMessage("");

      //åŠ å…¥ThinkingBubbleä¾†å‘Šè¨´ä½¿ç”¨è€…chatbotæ­£åœ¨è™•ç†è«‹æ±‚
      setMessages((prevMessages) => [
        ...prevMessages,
        { role: "assistant", content: <ThinkingBubble sx={{ marginBottom: '-5px' }} />, text: <ThinkingBubble sx={{ marginBottom: '-5px' }} />, key: "thinking" },
        //theme?
      ]);

      //ä½¿ç”¨filterMessageObjectsä¾†å»ºç«‹ä¸€å€‹åªæœ‰roleå’Œcontentçš„arrayï¼Œç„¶å¾Œå†æŠŠæ–°çš„æ–‡å­—æ›´æ–°åˆ°arrayä¸­
      let messageObjects = filterMessageObjects(messages)
      messageObjects.push({ role: "user", content: message })

      try {
        //é€éAPI.postå°‡æ–‡å­—å‚³åˆ°å¾Œç«¯é€²è¡Œè™•ç†
        const response = await API.post("api", "/get-answer", {
          headers: {
            "Content-Type": "application/json",
          },
          body: {
            text: message,
            messages: messageObjects,
            isAudioResponse
          },
        })
        console.log(response);

        //å°‡ThinkingBubbleç§»é™¤
        setMessages((prevMessages) => {
          return prevMessages.filter((message) => message.key !== "thinking");
        });
        handleBackendResponse(response);

      }//è¼¸å‡ºéŒ¯èª¤ 
      catch (error) {
        console.error("Error sending text message", error.response || error.message || error);
        alert("Error sending text message", error.message);
      }


    }
  };

  const handleBackendResponse = (response, id = null) => {
    const generatedText = response.generated_text; //the ChatGPT answer
    const generatedAudio = response.generated_audio; //å¦‚æœisAudioResponseæ˜¯trueï¼ŒæŠŠç­”æ¡ˆè½‰æ›ä»¥å¾Œçš„audio
    const transcription = response.transcription;
    const audioElement = generatedAudio
      ? new Audio(`data: audio/mpeg;base64, ${generatedAudio}`)
      : null;
    const AudioMessage = () => (
      <span>
        {generatedText}{" "}
        {audioElement && (
          <IconButton
            aria-label="play-message"
            onClick={() => {
              audioElement.play();
            }}
          >
            <VolumeUpIcon style={{ cursor: "pointer" }} fontSize="small" />
          </IconButton>
        )}
      </span>
    );
    if (id) {
      setMessages((prevMessages) => {
        const updatedMessages = prevMessages.map((message) => {
          if (message.id && message.id === id) {
            return {
              ...message,
              content: transcription,
            };
          }
          return message;
        });
        return [
          ...updatedMessages,
          {
            role: "assistant",
            content: generatedText,
            audio: audioElement,
            text: <AudioMessage />,
          },
        ];
      });
    } else {
      // Simply add the response when no messageId is involved
      setMessages((prevMessages) => [
        ...prevMessages,
        {
          role: "assistant",
          content: generatedText,
          audio: audioElement,
          text: <AudioMessage />,
        },
      ]);
    }
  }

  return (
    <Container maxWidth="sm" sx={{ pt: 2 }}>
      <ChatHeader />
      <ChatMessages messages={messages} />
      <AudioControls isAudioResponse={isAudioResponse} filterMessageObjects={filterMessageObjects} messages={messages} setMessages={setMessages} handleBackendResponse={handleBackendResponse} />
      <MessageInput message={message} setMessage={setMessage} isAudioResponse={isAudioResponse} handleSendMessage={handleSendMessage} handleBackendResponse={handleBackendResponse} />
      <ResponseFormatToggle isAudioResponse={isAudioResponse} setIsAudioResponse={setIsAudioResponse} />
    </Container>
  );
}

//AudioControl å°±æ˜¯åœ¨æ§åˆ¶éŒ„éŸ³ï¼Œæ’­æ”¾ï¼Œæš«åœéŒ„éŸ³çš„åŠŸèƒ½
//AudioControl ä¸æ”¾åœ¨App functionè£¡é¢æ˜¯ç‚ºäº†è®“ä»–æ›´å¥½å°è£çµæ§‹è·Ÿé‚è¼¯ï¼Œä»¥åŠæ–¹ä¾¿ç®¡ç†ç¶­è­·
const AudioControls = ({isAudioResponse, filterMessageObjects, messages, setMessages}) => {
  const [isRecording, setIsRecording] = useState(false);
  const [recorder, setRecorder] = useState(null);
  const [player, setPlayer] = useState(null);
  const [audioFile, setAudioFile] = useState(null);

  const startRecording = async () => {
    //é€™æ˜¯ä¸€å€‹ä¸åŒæ­¥çš„function(å› ç‚ºä½¿ç”¨async)ï¼Œé€™æ¨£å¯ä»¥awaitç³»çµ±æŠ“åˆ°MicRecorderå†ç¹¼çºŒä¸‹å»
    const newRecorder = new MicRecorder({ bitRate: 128 });
    //æ–°å¢ä¸€å€‹MicRecorder å«åšnewRecorderï¼Œè¨­å®šéŸ³è³ª128bit
    try {
      await newRecorder.start();
      //é–‹å§‹éŒ„éŸ³
      setIsRecording(true);
      //éŒ„éŸ³=true
      setRecorder(newRecorder);
      //è¨­å®šéŒ„éŸ³è®Šæ•¸
    } catch (e) {
      console.error(e);
      alert(e);
      //è¼¸å‡ºéŒ¯èª¤
    }
  }

  const stopRecording = async () => {
    //åŒæ¨£æ˜¯å€‹ä¸åŒæ­¥çš„functionä¾†ç­‰awaité€šéç¹¼çºŒåŸ·è¡Œç¨‹å¼ç¢¼
    if (!recorder) return;

    try {
      const [buffer, blob] = await recorder.stop().getMp3();
      //åœæ­¢éŒ„éŸ³ä¸¦ä¸”å–å¾—MP3æª”æ¡ˆï¼Œå¦‚æœæˆåŠŸï¼Œbufferè·Ÿblobè®Šæ•¸æœƒè¢«getMP3è³¦äºˆå€¼ç„¶å¾Œå›å‚³
      const audioFile = new File(buffer, "voice-message.mp3", {
        //é€™é‚Šå°±åœ¨æŠŠå‰›å‰›å›å‚³çš„audiofileçš„å€¼è®Šæˆä¸€å€‹çœŸæ­£çš„MP3file
        type: blob.type,
        lastModified: Date.now(),
        //ä½¿ç”¨ç¾åœ¨æ™‚é–“ä¾†ä½œç‚ºæœ€å¾Œä¿®æ”¹æ™‚é–“çš„å€¼
      });
      setPlayer(new Audio(URL.createObjectURL(audioFile)));
      //å‰µé€ ä¸€å€‹URLä¾†ä»£è¡¨é€™å€‹æª”æ¡ˆçš„ä½ç½®ï¼Œnew Audioçš„constructorå‰µå»ºä¸€å€‹æ–°çš„Audioç‰©ä»¶ä¾†ä½¿ç”¨é€™å€‹URL
      setIsRecording(false);
      setAudioFile(audioFile);
    } catch (e) {
      console.error(e);
      alert(e)
      //è¼¸å‡ºéŒ¯èª¤
    }
  }

  const playRecording = () => {
    if (player) {
      player.play();
    }
  }
  //ä¸ç”¨éå¤šè§£é‡‹ï¼Œå°±æ˜¯æœ‰playerçš„è©±å°±æ’­æ”¾

  return (
    <Container>
      <Box sx={{ width: "100%", mt: 4 }}>
        <Grid container spacing={2} justifyContent="flex-end">
          <Grid item xs={12} md>
            <IconButton
              color="primary"
              aria-label="start recording"
              onClick={startRecording}
              disabled={isRecording}
            // ä¸é›£ç†è§£ï¼Œå°±æ˜¯æŠŠonClickäº‹ä»¶è·Ÿlabelé‚„æœ‰é¡è‰²å®šç¾©å¥½
            >
              <MicIcon />
              {/* é€™å€‹å‹•ä½œæ˜¯æŠŠMicIconé€™å€‹Iconæ”¾é€²IconButtonè£¡é¢ï¼Œè®“ä»–æœ‰icon */}
            </IconButton>
          </Grid>
          <Grid item xs={12} md>
            <IconButton
              color="secondary"
              aria-label="stop recording"
              onClick={stopRecording}
              isaled={!isRecording}>
              <FiberManualRecordIcon />
            </IconButton>
          </Grid>
          <Grid item xs="auto">
            <Button
              variant="contained"
              disableElevation
              onClick={playRecording}
              disabled={isRecording}
            >
              Play recording
            </Button>
          </Grid>
          <SendButton audioFile={audioFile} isAudioResponse={isAudioResponse} filterMessageObjects={filterMessageObjects} messages={messages} setMessages={setMessages} />
        </Grid>
      </Box>
    </Container>
  )
}

//ResponseFormatToggleå°±æ˜¯åœ¨è¨­å®šswitchæ–æ¡¿çš„method
const ResponseFormatToggle = ({ isAudioResponse, setIsAudioResponse }) => {

  const handleToggleChange = (event) => {
    setIsAudioResponse(event.target.checked);
  };
  //è¢«æ’¥å‹•å¾Œè§¸ç™¼äº‹ä»¶setIsAudioResponse
  return (
    <Box sx={{ display: "flex", justifyContent: "center", marginTop: 2 }}>
      <FormControlLabel
        control={
          <Switch
            checked={isAudioResponse}
            onChange={handleToggleChange}
            color="primary"
          />
          //switchå°±æ˜¯é‚£å€‹æ–æ¡¿ï¼Œæ”¹è®Šæ™‚å‘¼å«handleToggleChange
        }
        label="Audio reponse"
      />
    </Box>
  )
}

const pulse = keyframes`
0% {
  transform: scale(1);
  opacity:1;}
50%{
  transform: scale(1.1);
  opacity:0.7;
}
100%{
  transform:scale(1);
  opacity:1;
}
`;
const ThinkingBubbleStyled = styled(MoreHorizIcon)`
  animation: ${pulse} 1.2s ease-in-out infinite;
  margin-bottom: -5px;
  `;
const ThinkingBubble = () => {
  const theme = useTheme();
  return <ThinkingBubbleStyled theme={theme} sx={{ marginBottom: '-5px' }} />;
};
const SendButton = ({ audioFile, isAudioResponse, filterMessageObjects, messages, setMessages, handleBackendResponse }) => {
  const theme = useTheme();
  const uploadAudio = async () => {
    //é¦–å…ˆå…ˆç¢ºèªé€™å€‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if (!audioFile) {
      console.log("No audio file to upload");
      return;
    }
    try {
      //ä½¿ç”¨FileReaderä¾†è®€å–éŸ³æª”
      const reader = new FileReader();

      //onloadendå°±æ˜¯æ‹¿ä¾†ç¢ºèªæª”æ¡ˆæ˜¯å¦è¢«å®Œå…¨è®€å–ï¼Œasyncç”¨ä¾†ç¢ºèªè®€å–ç¨‹åºåœ¨é€²ä¸€æ­¥è™•ç†å‰è¢«è®€å–æˆåŠŸ
      reader.onloadend = async () => {

        const base64Audio = reader.result;

        //ä½¿ç”¨ä¸€å€‹å”¯ä¸€çš„æ™‚é–“Idä¾†ç•¶ä½œé€™å€‹éŸ³æª”çš„æª”å
        const messageId = new Date().getTime();

        //å‰µå»ºä¸€å€‹è¨Šæ¯ç‰©ä»¶
        let messageObjects = filterMessageObjects(messages)

        //æŠŠä½¿ç”¨è€…çš„èªéŸ³è¨Šæ¯åŠ å…¥åˆ°è¨Šæ¯é™£åˆ—ä¸­
        setMessages((prevMessages) => [
          ...prevMessages,
          { role: "user", content: "ğŸ¤ Audio Message", audio: new Audio(base64Audio), text: "ğŸ¤ Audio Message", id: messageId },
        ]);

        // é¡¯ç¤ºThinkingBubble iconä¾†è¡¨ç¤ºæ©Ÿå™¨äººæ­£åœ¨æ€è€ƒå›æ‡‰
        setMessages((prevMessages) => [
          ...prevMessages,
          { role: "assistant", content: <ThinkingBubble theme={theme} sx={{ marginBottom: '-5px' }} />, text: <ThinkingBubble theme={theme} sx={{ marginBottom: '-5px' }} />, key: "thinking" },
        ]);

        //ä½¿ç”¨API.postä¾†å‚³é€éŸ³æª”ã€è¨Šæ¯ã€é‚„æœ‰isAudioResponse(boolean)åˆ°å¾Œç«¯ä¾†è™•ç†
        const response = await API.post("api", "/get-answer", {
          headers: {
            "Content-Type": "application/json",
          },
          body: {
            audio: base64Audio,
            messages: messageObjects,
            isAudioResponse
          },
        });

        //å°‡å‰›å‰›çš„ThinkingBubbleç§»é™¤
        setMessages((prevMessages) => {
          return prevMessages.filter((message) => message.key !== "thinking");
        });
        handleBackendResponse(response, messageId);
      };
      //ä½¿ç”¨URLä¾†è®€å–éŸ³æª”
      reader.readAsDataURL(audioFile);

    } catch (error) {
      console.error("Error uploading audio file:", error);
      alert(error)
    }
  }
  return (
    <Grid item xs="auto">
      <Button
        variant="contained"
        color="primary"
        disableElevation
        onClick={uploadAudio}

        disabled={!audioFile}
        startIcon={<CloudUploadIcon />}
      >
        Upload Audio
      </Button>
    </Grid>
  )
}


const MessageInput = ({ message, setMessage, isAudioResponse, handleSendMessage }) => {
  const handleInputChange = (event) => {
    setMessage(event.target.value);
  }
  const handleKeyPress = (event) => {
    if (event.key === "Enter") {
      handleSendMessage();
    }
  }
  return (
    <Box sx={{ display: "flex", alignItems: "center", marginTop: 2 }}>
      <TextField
        variant="outlined"
        fullWidth
        label="Type your message"
        value={message}
        onChange={handleInputChange}
        onKeyPress={handleKeyPress}
      />
      <IconButton
        color="primary"
        onClick={() => handleSendMessage(isAudioResponse)}
        disabled={message.trim() === ""}
      >
        <SendIcon />
      </IconButton>
    </Box>
  );
}


export default App;